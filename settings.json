{
	"general_params" : {
		"seed" 							: 0,
	  	"num_of_episodes" 				: 300,
	  	"mode"							: {"train" : 0, "test" : 1}
	},
	"agent_params" : {
		"state_size"					: -1,
		"action_size"					: -1,
		"learning_rate_actor" 			: 0.001,
		"learning_rate_policy"			: 0.0005,
        "learning_rate_critic" 			: 0.002,
		"learning_rate_value_fn"		: 0.0005,
		"gamma" 						: 0.99,
		"tau" 							: 0.001,
		"updates_num"					: 10,
        "baseline_epochs"               : 5,
        "ppo_epochs"                    : 3,
        "ppo_epsilon"                   : 0.2,
		"buf_params" 					: {"buffer_size" : 1000, "batch_size" : 128},
		"nn_params"						: {"nn_actor" : {"l1" : [-1, 128], "l2" : [128, 64], "l3" : [64, -1]},
											"nn_critic" : {"l1" : [-1, 128], "l2" : [128, 256], "l3" : [256, 128], "l4" : [128, 32], "l5" : [32, 1]},
											"nn_policy" : {"l1" : [-1, 128], "l2" : [128, 64], "l3" : [64, -1]},
                                            "nn_value_function" : {"l1" : [-1, 128], "l2" : [128, 256], "l3" : [256, 128], "l4" : [128, 32], "l5" : [32, 1]}}
	},
	"trainer_params" : {
		"learning_rate_decay" 			: 0.999,
		"t_max"							: 1000,
    	"results_path"					: "../results/",
    	"model_path"					: "../models/"
	},
	"env_params" : {
		"path"							: "../Reacher_app/Reacher-20.app",
		"seed"							: 0,
		"worker_id"						: 0,
		"visual_mode"					: false,
		"multiagent_mode"				: true
	}
}